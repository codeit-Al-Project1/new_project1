import torch
import torch.optim as optim
from tqdm import tqdm
import os
import sys
from torch.optim.lr_scheduler import ReduceLROnPlateau
from .data_loader import get_train_val_loader
from .model import get_model, save_model
from src.utils import evaluate_mAP

# ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
epochs = 20
learning_rate = 0.005
weight_decay = 1e-4
num_classes = 74  # ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ + ë°°ê²½
batch_size = 4 # ** ì¶”ê°€ **

# ë°ì´í„° ë¡œë“œ
train_loader, val_loader = get_train_val_loader(batch_size, val_ratio = 0.2, debug = False ) # ë°ì´í„° ë””ë ‰í† ë¦¬ ì¶”ê°€í•˜ê¸°

# ëª¨ë¸ ë¡œë“œ
model = get_model(num_classes).to(device)

# ì˜µí‹°ë§ˆì´ì €
optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay) # SGD or AdamW

# ìŠ¤ì¼€ì¥´ëŸ¬
scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)

# í•™ìŠµ í•¨ìˆ˜
def train(model, train_loader, optimizer, epoch):
    model.train()
    running_loss = 0.0
    loop = tqdm(train_loader, leave=False, desc=f"Epoch {epoch+1}/{epochs}")

    for images, targets in loop:
        images = [img.to(device) for img in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        optimizer.zero_grad()
        loss_dict = model(images, targets)
        loss = sum(loss for loss in loss_dict.values())
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        loop.set_postfix(loss=loss.item())

    return running_loss / len(train_loader)

# ê²€ì¦ í•¨ìˆ˜
def validate(model, val_loader):
    model.eval()
    val_loss = 0.0
    all_preds = []
    all_targets = []

    with torch.no_grad():
        loop = tqdm(val_loader, leave=False, desc="Validating")

        for images, targets in loop: # DataLoaderì—ì„œ ê°€ì ¸ì˜´
            images = [img.to(device) for img in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            loss_dict = model(images, targets)
            loss = sum(loss for loss in loss_dict.values())
            val_loss += loss.item()

            # mAP í‰ê°€ë¥¼ ìœ„í•œ ì˜ˆì¸¡ ì €ìž¥
            outputs = model(images)
            all_preds.extend(outputs)
            all_targets.extend(targets)

    mAP = evaluate_mAP(all_preds, all_targets)
    return val_loss / len(val_loader), mAP

# í•™ìŠµ ë£¨í”„
best_mAP = 0.0
os.makedirs("checkpoints", exist_ok=True)

for epoch in range(epochs):
    print(f"\nðŸ”¹ Epoch {epoch+1}/{epochs} ì‹œìž‘")

    train_loss = train(model, train_loader, optimizer, epoch)
    val_loss, mAP = validate(model, val_loader)

    print(f"ðŸ“‰ Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, mAP: {mAP:.4f}")

    scheduler.step(val_loss)

    if mAP > best_mAP:
        best_mAP = mAP
        save_model(model)
        print("âœ… Best model saved!")

print("Training Complete!")
